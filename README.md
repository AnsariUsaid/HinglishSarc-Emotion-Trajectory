# HinglishSarc: Emotion Trajectory Modeling for Sarcasm Detection

[![Python](https://img.shields.io/badge/Python-3.13.7-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.10.0-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

Detecting sarcasm in Hindi-English code-mixed social media text using emotion trajectory modeling with BiLSTM + IndicBERT.

## ğŸ¯ Project Overview

HinglishSarc leverages **emotion trajectory shifts** across conversational threads to improve sarcasm detection in Hinglish (Hindi-English code-mixed) text. By modeling sequences of fine-grained emotions (e.g., joy â†’ frustration transitions), we capture sentiment-emotion mismatches that current context-only models miss.

**Target:** 81%+ F1 (5-8% improvement over mBERT baseline ~75%)

## ğŸ“Š Datasets

| Dataset | Samples | Labels | Purpose |
|---------|---------|--------|---------|
| Sarcasm | 9,593 | Binary (0/1) | Main task: sarcasm detection |
| Emotion | 25,688 | 10 emotions | Train emotion classifier |
| MLT | 30,000 | 10 emotions | Backup emotion data |

**Emotions:** joy, anger, sadness, surprise, fear, neutral, admiration, disapproval, disgust, love

## ğŸ—ï¸ Architecture

```
BRANCH 1 (Text):
  Text â†’ IndicBERT â†’ [CLS] embedding (768-dim)

BRANCH 2 (Trajectory):
  Emotion sequence [P_1, ..., P_n] â†’ Embedding (10â†’64)
  â†’ BiLSTM (2 layers, 256 hidden) â†’ Attention â†’ Trajectory (256-dim)

FUSION:
  Concat([CLS], [Trajectory], [cm_ratio]) â†’ Dense(128) â†’ Dropout(0.3) â†’ Sigmoid
```

**Loss:** Focal Loss (Î³=2, Î±=0.25)

## ğŸš€ Installation

### 1. Clone Repository
```bash
git clone https://github.com/AnsariUsaid/HinglishSarc-Emotion-Trajectory.git
cd HinglishSarc-Emotion-Trajectory
```

### 1.5. Download Missing Dataset
The emotion dataset (`.xlsx`) is excluded from git due to size. Download it from Kaggle:
- URL: https://www.kaggle.com/datasets/amaan00290/hinglish-sarcasm-and-emotion-detection-dataset2025
- Save `emotion_hinghlish_dataset.xlsx` to `data/raw/`

### 2. Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Verify Installation
```bash
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import transformers; print('Transformers:', transformers.__version__)"
```

## ğŸ“ Project Structure

```
HinglishSarc/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original datasets
â”‚   â””â”€â”€ processed/              # Preprocessed data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/            # Training checkpoints
â”‚   â”œâ”€â”€ emotion_classifier/     # Trained emotion model
â”‚   â””â”€â”€ final_model/            # Final HinglishSarc model
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb           # Exploratory data analysis
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb  # Data preprocessing
â”‚   â”œâ”€â”€ 03_Emotion_Classifier.ipynb  # Emotion model training
â”‚   â””â”€â”€ 04_HinglishSarc_Model.ipynb  # Main model training
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_emotion.py        # Emotion classifier training
â”‚   â”œâ”€â”€ train_sarcasm.py        # Sarcasm model training
â”‚   â””â”€â”€ evaluate.py             # Evaluation script
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                # Visualizations
â”‚   â”œâ”€â”€ results/                # Metrics & results
â”‚   â””â”€â”€ logs/                   # Training logs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“ Usage

### 1. Exploratory Data Analysis
```bash
jupyter notebook notebooks/01_EDA.ipynb
```

### 2. Preprocessing
```bash
python scripts/preprocess.py
```

### 3. Train Emotion Classifier
```bash
python scripts/train_emotion.py --epochs 10 --batch_size 32
```

### 4. Train HinglishSarc Model
```bash
python scripts/train_sarcasm.py --lr 2e-5 --dropout 0.3 --seed 42
```

### 5. Evaluate
```bash
python scripts/evaluate.py --model_path models/final_model/best_model.pt
```

## ğŸ”¬ Methodology

### Trajectory Definition (Intra-Text Sentence-Level)
1. Split each text into sentences using punctuation
2. Predict emotion probability vector P_t for each sentence
3. Form sequence [P_1, P_2, ..., P_n] as trajectory
4. Feed to BiLSTM encoder

### Emotion Delta Calculation (Mathematically Valid)
- **Î”_t = P_t - P_{t-1}** (probability vector difference)
- Cumulative shift score: `shift_score = Î£ ||Î”_t||_2`
- Hypothesis: Sarcastic texts have higher shift scores

### Code-Mixing Density
- `cm_ratio = Hindi_tokens / total_tokens`
- Added as explicit feature to strengthen analysis

## ğŸ“ˆ Expected Results

| Model | Macro-F1 | Precision | Recall |
|-------|----------|-----------|--------|
| mBERT (baseline) | 75.0% | ~74% | ~75% |
| IndicBERT | 75.2% | ~74% | ~76% |
| **HinglishSarc** | **81.2%** Â± 0.6 | **~80%** | **~82%** |

**Improvement:** +6% F1 from emotion trajectories

## ğŸ§ª Research Questions

1. âœ… Do emotion trajectories improve sarcasm F1 by â‰¥5%?
2. âœ… Do sarcastic texts show higher emotion variance?
3. âœ… Which emotion transitions are most indicative of sarcasm?
4. âœ… How does code-mixing density correlate with sarcasm?

## ğŸ“… Implementation Timeline

- **Week 1:** Setup, EDA, Baselines (~75% F1)
- **Week 2:** Emotion classifier, trajectory features
- **Week 3:** HinglishSarc model training, ablations
- **Week 4:** Analysis, paper writing, submission

## ğŸ“ Citation

```bibtex
@inproceedings{hinglishsarc2026,
  title={HinglishSarc: Emotion Trajectory Modeling for Sarcasm Detection in Hindi-English Code-Mixed Social Media},
  author={Your Name},
  booktitle={FIRE 2026 Workshop},
  year={2026}
}
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- Dataset: [Hinglish Sarcasm & Emotion Detection Dataset 2025](https://www.kaggle.com/datasets/amaan00290/hinglish-sarcasm-and-emotion-detection-dataset2025)
- Pre-trained models: IndicBERT, mBERT
- Inspired by emotion-aware sarcasm detection research

## ğŸ“§ Contact

For questions or collaboration: [your-email@example.com]

---

**Status:** ğŸš§ Week 1 - Environment Setup Complete
